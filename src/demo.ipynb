{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Change Analysis Interface\n",
    "\n",
    "Use this notebook to interactively analyze semantic changes of words over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown, clear_output, HTML\n",
    "\n",
    "# Import our library modules\n",
    "from semantic_change.corpus import CorpusManager\n",
    "from semantic_change.embedding import BertEmbedder\n",
    "from semantic_change.wsi import WordSenseInductor\n",
    "from semantic_change.visualization import Visualizer\n",
    "\n",
    "# Helper to display documentation\n",
    "def show_docs():\n",
    "    if os.path.exists(\"user_guide.md\"):\n",
    "        with open(\"user_guide.md\", \"r\") as f:\n",
    "            display(Markdown(f.read()))\n",
    "    else:\n",
    "        print(\"User guide not found.\")\n",
    "\n",
    "show_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration & Setup\n",
    "Configure your data paths below. By default, it uses the `data/` directory created by the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI Widgets\n",
    "path_input = widgets.Text(value='data', description='Data Root:', placeholder='Path to data folder')\n",
    "word_input = widgets.Text(value='bank', description='Focus Word:', placeholder='e.g., apple')\n",
    "sample_slider = widgets.IntSlider(value=50, min=10, max=500, step=10, description='Samples:')\n",
    "cluster_slider = widgets.IntSlider(value=2, min=2, max=10, step=1, description='Clusters:')\n",
    "run_btn = widgets.Button(description=\"Run Analysis\", button_style='success', icon='play')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "display(widgets.VBox([path_input, word_input, sample_slider, cluster_slider, run_btn]))\n",
    "\n",
    "# Global model variable to load only once if possible (though class re-init is safer for memory in notebooks)\n",
    "embedder = None\n",
    "\n",
    "def run_analysis(b):\n",
    "    global embedder\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        root_path = path_input.value\n",
    "        target_word = word_input.value\n",
    "        n_samples = sample_slider.value\n",
    "        n_clusters = cluster_slider.value\n",
    "        \n",
    "        print(f\"Processing '{target_word}' from '{root_path}'...\")\n",
    "        \n",
    "        if not os.path.exists(root_path):\n",
    "            print(f\"Error: Path '{root_path}' does not exist.\")\n",
    "            return\n",
    "\n",
    "        # 1. Load Corpora\n",
    "        manager = CorpusManager()\n",
    "        subdirs = [d for d in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, d))]\n",
    "        subdirs.sort()\n",
    "        \n",
    "        if not subdirs:\n",
    "            print(\"No subdirectories found in data path. Expected format: data/corpus_1990, data/corpus_2000 etc.\")\n",
    "            return\n",
    "            \n",
    "        for d in subdirs:\n",
    "            manager.add_corpus(d, os.path.join(root_path, d))\n",
    "            print(f\"Loaded corpus: {d}\")\n",
    "\n",
    "        # 2. Extract Embeddings\n",
    "        if embedder is None:\n",
    "            print(\"Loading BERT model (this may take a moment)...\\n\")\n",
    "            embedder = BertEmbedder()\n",
    "        \n",
    "        all_embeddings = []\n",
    "        all_sentences = []\n",
    "        time_labels = []\n",
    "        \n",
    "        for name in manager.corpora:\n",
    "            print(f\"Querying '{name}'...\")\n",
    "            samples = manager.get_corpus(name).query_samples(target_word, n=n_samples)\n",
    "            if not samples:\n",
    "                print(f\"  - No samples found for '{target_word}' in {name}\")\n",
    "                continue\n",
    "                \n",
    "            embs, sents = embedder.get_embeddings(samples, target_word)\n",
    "            if len(embs) > 0:\n",
    "                all_embeddings.append(embs)\n",
    "                all_sentences.extend(sents)\n",
    "                time_labels.extend([name] * len(embs))\n",
    "                print(f\"  - Retrieved {len(embs)} embeddings.\")\n",
    "\n",
    "        if not all_embeddings:\n",
    "            print(\"No data found for analysis. Check your word spelling or data path.\")\n",
    "            return\n",
    "            \n",
    "        X = np.vstack(all_embeddings)\n",
    "        \n",
    "        # 3. WSI Clustering\n",
    "        print(f\"\\nRunning WSI (k={n_clusters})...\")\n",
    "        wsi = WordSenseInductor(n_clusters=n_clusters)\n",
    "        sense_labels = wsi.fit_predict(X)\n",
    "        \n",
    "        # 4. Visualization\n",
    "        viz = Visualizer(method='pca')\n",
    "        \n",
    "        print(\"\\n--- Visualizing by Time Period ---\")\n",
    "        viz.plot_clustering(X, time_labels, all_sentences, title=f\"'{target_word}' by Time Period\")\n",
    "        \n",
    "        print(\"\\n--- Visualizing by Sense Cluster ---\")\n",
    "        viz.plot_clustering(X, sense_labels, all_sentences, title=f\"'{target_word}' by Sense Cluster\")\n",
    "        \n",
    "        print(\"\\n--- Semantic Neighbors (MLM Projection) ---\")\n",
    "        unique_clusters = sorted(list(set(sense_labels)))\n",
    "        for cluster_id in unique_clusters:\n",
    "            mask = (sense_labels == cluster_id)\n",
    "            centroid = np.mean(X[mask], axis=0)\n",
    "            neighbors = embedder.get_nearest_neighbors(centroid, k=8)\n",
    "            \n",
    "            print(f\"Cluster {cluster_id} top keywords: {list(neighbors.keys())}\")\n",
    "            viz.plot_neighbors(centroid, neighbors, title=f\"Cluster {cluster_id} Context Projection\")\n",
    "\n",
    "run_btn.on_click(run_analysis)\n",
    "display(output_area)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
